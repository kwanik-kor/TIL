# 1. 처리량과 응답시간

## 1.1 응답시간

> 사용자의 요청을 처리하는데 걸리는 시간

전형적인 API 호출 과정을 기준으로 보면, 다음의 단계를 거치게 되고 이 요청을 처리하는데 걸린 시간을 응답시간으로 볼 수 있다.
- 서버에 연결
	- TCP를 이용해 서버 연결
- 서버로 데이터 전송
	- 프로토콜에 따라 데이터를 전송하는데, HTTP 프로토콜에 따라 JSON 데이터를 POST 방식으로 전송할 수 있음
- 서버 실행(비즈니스 로직 수행)
	- DB 연동, 로직 수행, 외부 API 연동, 응답 데이터 생성
- 클라이언트로 데이터 전송

응답 시간은 크게 2가지로 나누어 측정할 수 있다.
- TTFB(Time to First Byte): 첫 번째 바이트가 도착할 때까지 걸린 시간
- TTLB(Time to Last Byte): 마지막 바이트가 도착할 때까지 걸린 시간

> 응답 시간이 길어질수록 사용자의 검색 횟수, 매출은 감소한다.

## 1.2 처리량

> 단위 시간당 시스템이 처리하는 작업량

초당 트랜잭션 수와 초당 요청 수 등 다양한 측정 지표가 있지만 보편적으로 TPS를 사용한다.
- TPS(Transaction Per Second)
- RPS(Request Per Second)

최대 TPS란 시스템이 처리할 수 있는 최대 요청 수를 의미하며, 최대 TPS가 5인 경우 7의 요청이 들어왔을 때 2의 요청은 대기하는 상태가 된다. 지연 상태가 길어지면 이탈에 직접적인 영향을 주므로, 2가지 방법을 고려할 수 있다.
- 서버가 동시에 처리할 수 있는 **요청 수를 늘려** 대기 시간 줄이기
- **처리 시간 자체를 줄여** 대기 시간 줄이기

# 2. 서버 성능 개선 기초
## 2.1 병목 지점

서비스 초기에는 성능 문제가 잘 발생하지 않는다. 사용자 수가 늘어남에 따라 트래픽이 늘고 데이터가 쌓임에 따라 응답시간이 점점 느려지는 현상이 발생하게 된다. 이러한 현상이 주로 발생하는 이유는 시스템이 수용할 수 있는 최대 TPS를 초과하는 트래픽이 유입되기 때문이다.

성능 문제를 해결하기 위해서는 문제가 발생하는 **병목지점**을 찾아야 한다.
- 모니터링 도구를 이용해 처리 시간이 오래 걸리는 작업 식별하기

## 2.2 수직 확장과 수평 확장

### 2.2.1 수직 확장(scale-up)

> 급한 불을 끄는 방법으로 CPU, 메모리, 디스크 등의 자원을 증가시켜 시도할 수 있는 방법

- 즉각적인 효과를 얻을 수 있음
- 하지만 언젠가는 동일한 문제가 발생함
- 비쌈

### 2.2.2 수평 확장(scale-out)

> 서버를 추가로 투입해 TPS를 높이는 방법

- 로드 밸런서를 이용해 트래픽을 골고루 분산하게됨
	- 정적 로드밸런싱: 라운드 로빈, IP 해시 방식
	- 동적 로드밸런싱: 서버 상태에 따라 트래픽을 분산하는 방식
- TPS를 높이기 위해 무작정 서버를 추가하면 안됨
	- DB에 문제가 있는데 서버를 추가로 투칩하면 불에 기름을 갖다 붓게됨

## 2.3 DB 커넥션 풀

> 서버와 DB는 네트워크 통신을 통해 연결되는데, 연결을 생성하고 종료하는 데 긴 시간이 걸림에 따라 매 요청마다 DB를 연결하고 종료하면 결국 전체 응답 시간에 영향을 주게 된다. 이런 문제를 피하기 위해 서버는 DB 커넥션 풀을 사용한다.

- 애플리케이션은 DB에 연결된 커넥션을 미리 생성해서 보관
	- DB 작업이 필요할 때 풀에서 커넥션을 가져와 사용하고 반납
- 커넥션 풀 크기(Connection pool size)
	- 미리 생성해둘 커넥션 개수를 지정하는 설정
	- 서버는 주로 DB와 통신하므로, **적절한 커넥션 풀 크기 설정**이 매우 중요
	- 최소 크기와 최대 크기를 설정하여, 트래픽이 몰리는 시간대에 유동적으로 풀 크기를 관리할 수 있도록 조치
- 커넥션 대기 시간(Connection timeout)
	- 풀에 사용할 수 있는 커넥션이 없을 때 커넥션을 얻기 위해 기다릴 수 있는 최대 시간
	- Hikari CP default 30s
	- 응답 시간이 중요한 서비스의 경우 커넥션 대기 시간을 가능한 한 짧게 설정해야 함 (0.5 ~ 3)
	- 커넥션을 얻지 못할 경우 빠르게 에러를 응답하는 것이 서버 부하를 줄일 수 있음
		- 대기 시간이 길어질 경우, 요청을 취소하고 재요청이 발생함에 따라 트래픽이 더 증가하게 됨
		- 커넥션 풀 10개, 대기 시간 30초, 쿼리 시간 5초라고 가정해서 생각해보기
	- 

---
# 심화

### 1. 응답시간과 처리량을 측정할 수 있는 도구는 어떤 게 있을까?

 
### 2. TTLB는 마지막 바이트가 도착했다는 것을 어떤 기준으로 측정하게 되는 걸까?

> 네트워크 계층에서 소켓이 더 이상 읽을 데이터가 없음을 인지했을 때

HTTP 프로토콜인 경우
- Content-length 헤더가 있으면, 지정한 바이트 수 만큼 데이터를 읽었을 때 마지막 바이트 도착으로 간주
- Transfer-Encoding: chunked의 경우, "0\r\n\r\n" (chunk 종료 표시)을 받았을 때 마지막 바이트 도착으로 간주
- HTTP/2/3의 경우: 스트림 종료 플래그(`END_STREAM`)가 도착하면 마지막 바이트로 판단
### 3. Spring에서 최대 TPS가 초과되어 대기하는 요청들은 어디서 대기할까?

- **Spring MVC (Tomcat/NIO 환경)**
    
    1. 클라이언트 요청 → Tomcat Connector가 먼저 받음.
        
    2. **Tomcat의 Acceptor Thread**가 소켓 연결을 받고, **요청 큐**(accept queue / backlog)에 저장.
        
    3. ThreadPoolExecutor(Worker Threads)에서 요청을 가져가 처리.
        
    4. 스레드가 부족하면 요청은 **Tomcat의 내부 큐**에서 대기.
        
    5. 큐가 가득 차면 → 클라이언트에 `503 Service Unavailable` 응답.
        

즉, **Spring 자체가 아니라 WAS(Tomcat, Undertow, Jetty)** 수준의 스레드 풀과 큐에서 대기

### 4. 언제 어떻게 수직/수평 확장을 적용했었나?


### 5. Spring Boot의 기본 커넥션 풀인 Hikari CP는 어떻게 구성되어 있을까?

- Spring Boot 2.x+ 기본 커넥션 풀은 **HikariCP**
    
- 주요 기본값:
    
    - `maximumPoolSize = 10`
        
    - `minimumIdle = 10` (기본적으로 maximumPoolSize와 동일)
        
    - `connectionTimeout = 30s` (풀에서 커넥션 못 빌리면 예외)
        
    - `idleTimeout = 600s` (사용되지 않는 커넥션은 제거)
        
    - `maxLifetime = 1800s` (DB 커넥션 재생성 주기 → DB 측 idle timeout과 맞추는 게 중요)

### 6. 적절한 기본 커넥션 풀 크기를 설정하는 공식이 있을까? 공식이 있다면 어떤 기준으로 만들어진걸까?

- **일반적으로 알려진 공식 (C3P0/Hikari 문서에서 차용됨)**
    

Pool Size≈(Number of CPU cores)×(1+DB Wait TimeDB Service Time)\text{Pool Size} \approx \text{(Number of CPU cores)} \times (1 + \frac{\text{DB Wait Time}}{\text{DB Service Time}})Pool Size≈(Number of CPU cores)×(1+DB Service TimeDB Wait Time​)

- **DB Wait Time**: 애플리케이션이 DB 응답을 기다리는 평균 시간
    
- **DB Service Time**: 실제 쿼리가 DB에서 처리되는 시간
    

이 공식은 **리틀의 법칙(Little’s Law)**을 기반으로 만들어졌습니다.

- 시스템 내 동시 처리 가능한 작업 수 = 처리율 × 평균 응답시간
    
- 풀 크기를 너무 크게 하면 DB에 과부하 → 성능 저하
    
- 너무 작으면 애플리케이션에서 대기 시간이 늘어남.
    

👉 실무에서는 보통 **CPU 코어 수 × 2~4 정도에서 시작 → 모니터링 → 조정** 방식으로 튜닝합니다.

### 7. DBMS는 부하가 걸리면 쿼리 실행 시간이 왜 느려질까?

주요 원인:

1. **동시 연결 과다**
    
    - DB Connection이 너무 많아지면 Context Switching, Lock 경합 증가.
        
2. **락/경합**
    
    - 같은 데이터에 대해 많은 트랜잭션이 동시에 접근하면 **Row Lock, Table Lock, Deadlock 회피** 때문에 대기.
        
3. **Buffer Pool/Cache Miss 증가**
    
    - 메모리 캐시가 부족해지면 → 디스크 I/O 발생 → 응답 느려짐.
        
4. **쿼리 플랜 선택 오류**
    
    - 통계 정보가 부정확하면 옵티마이저가 비효율적인 실행 계획 선택.
        
5. **리소스 부족**
    
    - CPU, 메모리, 디스크 I/O, 네트워크 대역폭 부족 → 전체 쿼리 속도 저하.
        
6. **TempDB / Disk Spill**
    
    - 대량 정렬/조인 시 메모리가 부족해 디스크 쓰기를 하면 급격히 느려짐.



7. 서비스 속도가 느려졌을 때 **문제를 진단하는 일반적인 접근 순서**를 설명해 주세요.
    
8. **애플리케이션 병목**을 확인할 수 있는 방법에는 어떤 것이 있을까요?
    
9. **TPS와 응답 지연(latency)**은 어떻게 측정하고, 각각이 의미하는 바는 무엇인가요?
    
10. GC 튜닝이 서비스 성능에 영향을 줄 수 있는데, **GC가 원인인지 확인하는 방법**은 무엇인가요?
    
11. **스레드 덤프(Thread Dump)**를 분석하는 방법과 어떤 상황에서 활용하는지 설명해 보세요.
    
12. 서비스 장애 시, **네트워크 지연 문제**와 **애플리케이션 지연 문제**를 구분하는 방법은 무엇인가요?
    
13. **CPU 사용량이 높을 때**와 **메모리 사용량이 높을 때** 각각 어디를 먼저 의심해야 하나요?
    
14. APM(Application Performance Monitoring) 도구를 활용할 때, **가장 먼저 확인해야 하는 지표**는 무엇인가요?
    
15. 서비스가 느려졌을 때, **캐시를 추가하는 것이 좋은 해결책이 아닌 경우**는 언제일까요?
    
16. 실무에서 성능 문제의 **근본 원인(RCA, Root Cause Analysis)**을 찾기 위해 어떤 프로세스를 따르나요?

우리의 CDN 정말 의미있는 걸까요?


---

- 왜 gRPC를 모두 안쓰는걸까?
- 웹소켓과 소켓의 차이
	- 웹 소켓은 소켓의 종류 중 하나
- 