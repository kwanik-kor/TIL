# 1. 운영체제의 큰 그림
> 다양한 종류의 OS가 존재하지만 종류에 관계 없이 운영체제가 제공하는 핵심적인 기능은 유사함

**커널(kernel)**
- 운영체제의 핵심 기능을 담당하는 부분

**운영체제의 핵심 기능**
- 자원 할당 및 관리
	- **자원(resource)** / 시스템 자원
		- 프로그램 실행에 마땅히 필요한 요소
		- 실행에 필요한 데이터(S/W)
		- 실행에 필요한 부품(H/W)
	- 사용자가 실행하는 응용 프로그램을 대신하여 CPU, 메모리, 보조기억장치 등 컴퓨터 부품에 접근하고, 각 부품들이 효율적으로 사용되도록 관리
- 프로세스 및 스레드 관리

## 1.1 운영체제의 역할

### 1.1.1 CPU 관리: CPU 스케줄링
> 메모리에 실행 중인 프로그램이 다수 적재될 수 있으나, CPU가 이 모두를 동시에 실행할 수는 없음

운영체제는 실행 중인 모든 프로그램들이 공정하고 합리적으로 CPU를 할당받도록 CPU 할당 순서와 사용 시간을 결정해야 함

### 1.1.2 메모리 관리: 가상 메모리

운영체제는 새롭게 실행하는 프로그램을 메모리에 적재하고, 종료된 프로그램을 메모리에서 삭제함. 
동시에 낭비되는 메모리 용량이 없도록 효율적으로 관리해야 함
- 가상 메모리 기술 활용

### 1.1.3 파일/디렉터리 관리: 파일 시스템

메모리보다 더 큰 용량을 갖고 있는 보조기억장치는 더욱 일목요연하게 관리해야 함
보조기억장치를 효율적으로 관리하기 위해 파일 시스템을 활용함

### 1.1.4 프로세스 및 스레드 관리

**프로세스(process)**: 실행중인 프로그램
**스레드(thread)**: 프로세스를 이루는 실행의 단위

메모리에 적재될 수 잇는 여러 프로세스에 필요한 자원을 할당하고, 스레드는 프로세스가 할당받은 자원을 이용해 프로세스의 작업을 수행함

운영체제는 동시다발적으로 실행되는 프로세스와 스레드가 올바르게 처리되도록 실행 순서 제어 및 프로세스와 스레드가 요구하는 자원을 적절하게 배분할 수 있어야 함

## 1.2 시스템 콜과 이중 모드

**커널 영역(kernel space)**
- 운영체제도 프로그램이기 때문에 적재되어야 하는데, 운영체제가 적재되는 별도의 공간
- 운영체제 기능을 제공받기 위해서는 커널 영역의 운영체제 코드를 실행해야 함

**사용자 영역(user space)**
- 운영체제가 적재되는 커널 영역 외에 사용자 응용 프로그램이 적재되는 공간

**응용 프로그램이 운영체제의 코드를 실행할 수 있는 방법**
- **시스템 콜(system call)** 호출
	- 운영체제의 서비스를 제공받기 위한 수단(인터페이스)
	- 호출 가능한 함수의 형태

**UNIX 계열 시스템 콜**

| 구분        | 시스템 콜     | 설명                  |
| --------- | --------- | ------------------- |
| 프로세스 관리   | fork()    | 새 자식 프로세스 생성        |
|           | execve()  | 프로세스 실행             |
|           | exit()    | 프로세스 종료             |
|           | waitpid() | 자식 프로세스가 종료할 때까지 대기 |
| 파일 관리     | open()    | 파일 열기               |
|           | close()   | 파일 닫기               |
|           | read()    | 파일 읽기               |
|           | write()   | 파일 쓰기               |
|           | stat()    | 파일 정보 획득            |
| 디렉터리 관리   | chdir()   | 작업 디렉터리 변경          |
|           | mkdir()   | 디렉터리 생성             |
|           | rmdir()   | 비어 있는 디렉터리 삭제       |
| 파일 시스템 관리 | mount()   | 파일 시스템 마운트          |
|           | umount()  | 파일 시스템 마운트 해제       |
> fork()를 통해 알 수 있듯이 프로세스는 시스템 콜을 통해 또 다른 프로세스를 생성할 수 있음


**시스템 콜에 의한 작업 수행 과정**
1. 소프트웨어 인터럽트 발생
	1. 입출력 명령어와 같이 명령어에 의해 발생하는 인터럽트
	2. 시스템 콜도 소프트웨어 인터럽트
2. CPU의 **커널 모드** 전환
	1. 커널 영역에 적재된 코드를 실행할 때의 실행모드
	2. 운영체제 서비스를 제공받을 수 있는 실행모드
3. 운영체제 코드 실행
4. **사용자 모드**로 재전환
	1. 사용자 영역에 적재된 코드를 실행할 때의 실행모드
	2. 운영체제 서비스를 제공받을 수 없는 실행모드

---
# 2. 프로세스와 스레드

## 2.1 **프로세스의 유형**
- **포그라운드 프로세스**
	- 사용자가 보는 공간에서 사용자와 상호작용하며 실행
- **백그라운드 프로세스**
	- 사용자가 보지 못하는 곳에서 실행
- **데몬**
	- 백그라운드 프로세스 중에서 사용자와 상호작용 없이 주어진 작업만 수행하는 프로세스
	- 윈도우에서는 서비스라고 함

## 2.2 **프로세스를 구성하는 메모리 내의 정보**
- **커널 영역**
	- **PCB(Process Control Block)**
		- 프로세스를 식별할 수 있는 커널 영역 내의 정보
		- 프로세스와 관련한 다양한 정보를 내포하는 구조체의 일종
		- 프로세스가 실행되면 커널에 만들어지고, 종료되면 폐기됨
		- 담기는 정보
			- PID
			- 실행 과정에서 사용한 레지스터 값
			- 프로세스 상태
			- CPU 스케줄링 정보
			- 메모리 관련 정보
			- 파일 및 입출력장치 관련 정보
		- 여러 PCB는 커널 내에 **프로세스 테이블** 형태로 관리되기도 함
			- 프로세스가 종료되었음에도 프로세스 테이블에 남아있는 경우 이 프로세스를 **좀비 프로세스**라고 함
- 사용자 영역
	- 코드 영역(code segment)
		- 실행 가능한 명령어가 저장되는 공간
		- 텍스트 영역(text segement)
		- CPU가 읽고 실행할 명령어가 있어 read-only
	- 데이터 영역(data segment)
		- 프로그램이 실행되는 동안 유지할 데이터가 저장되는 공간
		- 정적변수, 전역 변수
		- BSS(Block Started by Symbol) 영역
			- 데이터 영역과 유사
			- 초깃값이 없는 데이터는 BSS 영역에 저장
	- 힙 영역(heap segment)
		- 프로그램을 만드는 사용자가 직접 할당 가능한 저장 공간
		- 힙 영역에 할당했으면 언젠가는 반환해야 함
		- 메모리 반환을 하지 않을 경우 메모리 누수(memory leak) 발생 가능
	- 스택 영역(stack segment)
		- 일시적으로 사용할 값들이 저장되는 공간
		- 매개변수, 지역 변수, 함수 복귀 주소 등
		- 스택 트레이스(stack trace)
			- 특정 시점에 스택 영역에 저장된 함수 호출 정보

## 2.3 컨텍스트 스위칭
> 메모리에 적재된 프로세스들은 한정된 시간 동안 번갈아 가며 실행됨

프로세스가 실행된다 = 운영체제의 의해 CPU 자원을 할당 받았다.

**타이머 인터럽트(timer interrupt)**
- 프로세스의 CPU 사용 시간은 타이머 인터럽트에 의해 제어
- 시간이 끝났음을 알리는 인터럽트
- 타임아웃 인터럽트

인터럽트가 발생한 경우
- 프로세스 A의 컨텍스트를 해당 프로세스의 PCB에 백업
	- PC, 레지스터, 메모리, 파일, ...
	- 이러한 중간 정보를 **문맥(context)** 이라고 함
	- 프로세스 문맥은 해당 프로세스의 PCB에 명시
- 프로세스 B의 컨텍스트 복구
- 위와 같은 과정을 **문맥 교환(context switching)** 이라고 함

잦은 문맥 교환은 캐시 미스 발생률이 올라갈 수 있어, 메모리 내용을 가져오는 작업이 빈번해짐에 따라 오버헤드로 이어질 수 있음

## 2.4 프로세스 상태

**생성 상태(new)**
- 프로세스 생성 중인 상태
- 메모리에 적재되어 PCB 할당 받음

**준비 상태(ready)**
- CPU를 할당받아 실행할 수 있지만, 자신의 차례가 아니라 기다리는 상태
- 준비 상태에서 실행 상태로 전환되는 것을 **디스패치(dispatch)**

**실행 상태(running)**
- CPU를 할당받아 실행 중인 상태

**대기 상태(blocked)**
- 입출력 작업 요청, 확보할 수 없는 자원 요청 등 곧장 실행이 불가능한 조건에 놓이는 경우 대기 상태가 됨
- 실행 가능한 상태가 되면 준비 상태로 변경

**종료 상태(terminated)**
- PCB와 프로세스가 사용한 메모리 정리

**블로킹 입출력과 논블로킹 입출력**
- 블로킹 입출력(blocking I/O)
	- 입출력 작업을 수행해야 할 때 대기 상태로 접어들고, 완료되면 준비 상태가 되어 실행 재개
- 논블로킹 입출력(non-blocking I/O)
	- 입출력장치에게 입출력 작업을 맡긴 뒤, 곧바로 이어질 명령어 실행

## 2.5 멀티프로세스와 멀티스레드
> 한 프로세스를 구성하는 코드를 동시에 실행하려면 어떻게 해야 할까?

### 2.5.1 멀티프로세스
- 같은 프로그램을 각기 다른 프로세스로 만들어 실행
- 프로세스들이 자원을 공유하지 않고 독립적으로 실행됨
- 같은 작업을 수행해도 각각의 PID가 다름
	- ex) 크롬 웹 브라우저 탭

### 2.5.2 멀티스레드
- 하나의 스레드는 스레드를 식별할 수 있는 스레드 ID, 프로그램 카운터, 레지스터 값, 스택 등으로 구성됨
- 스레드마다 각각의 PC와 스택을 갖고 있어 스레드마다 다음 실행할 주소를 가질 수 있음
- 프로세스의 자원 공유
- 동일한 주소 공간의 코드, 데이터, 힙 영역을 공유
- 한 스레드의 문제가 프로세스 전체의 문제가 될 수 있음

## 2.6 프로세스 간 통신(IPC, Inter-Process Communication)
> 프로세스 간 자원을 공유하지 않지만, 이를 가능하게 하는 방법

### 2.6.1 공유 메모리(shared memory)
- 프로세스가 공통적으로 사용할 메모리 영역을 두는 방식
- 프로세스가 공유하는 메모리 영역을 확보하는 시스템 콜 기반으로 수행하거나, 변수나 파일을 활용할 수 있음
- 각 프로세스가 **마치 자신의 메모리 영역을 읽고 쓰는 것**처럼 통신함
- 커널의 개입이 거의 없음
- 메시지 전달 방식보다 속도가 빠름
- 일관성이 훼손될 수 있음
	- 레이스 컨디션(race condition)

### 2.6.2 메시지 전달
- 프로세스 간에 주고받을 데이터를 메시지의 형태로 주고받는 방식
- 시스템 콜
	- send()
	- recv()
- 커널의 도움을 받을 수 있어 레이스 컨디션, 동기화 등의 문제를 상대적으로 적게 고려해도 됨
- 공유 메모리 방식보다 느림

- 메시지 전달 기반 IPC의 수단
	- **파이프(pipe)**
		- 단방향 프로세스 간의 통신 도구(익명 파이프, unnamed pipe)
			- 부모, 자식 프로세스간에만 통신이 가능
		- 양방향 통신의 경우, 읽기용과 쓰기용 파이프 2개를 이용(지명 파이프, named pipe)
			- 임의의 프로세스 간에도 사용 가능
	- **시그널(signal)**
		- 특정 이벤트가 발생했음을 알리는 비동기적인 신호
		- 대부분 인터럽트에 관련한 이벤트지만 사용자가 직접 정의할 수도 있음
		- 프로세스는 시그널 발생 시, 일을 중단하고 **시그널 핸들러(signal handler)**를 실행한 뒤 실행 재개
	- **원격 프로시저 호출(RPC, Remote Procedure Call)\**
		- 원격 코드를 실행하는 IPC 기술
		- 다른 프로세스의 원격 코드 실행
		- 대규모 트래픽 처리 환경, 서버 간 통신 환경에서 주로 사용
		- gRPC
	- 네트워크 소켓

---
# 3. 동기화와 교착 상태

**공유자원(shared resource)**
- 프로세스 혹은 스레드가 공유하는 자원
- 메모리, 파일, 전역 변수, 입출력장치 등

**임계구역(critical section)**
- 공유 자원에 접근하는 코드 중 동시에 실행했을 때 문제가 발생할 수 있는 코드
- 동시에 실행되는 프로세스나 스레드가 동시에 임계 구역에 진입하여 실행되면 문제가 될 수 있음
	- **레이스 컨디션(race condition)**
	- 둘 중 하나는 작업이 끝날 때까지 대기해야 함

```Java
public class Race {
	static int sharedData = 0;

	public static void main(String[] args) {
		Thread thread1 = new Thread(new Increment());
		Thread thread2 = new Thread(new Decrement());
		
		thread1.start();
		thread2.start();
		
		try {
			thread1.join();
			thread2.join();
		} catch (InterruptedException e) {
			e.printStackTrace();
		}

		System.out.println("Final value of sharedData: " + sharedData);
	}

	static class Increment implements Runnable {
		public void run() {
			for (int i = 0; i < 10000; i++) {
				sharedData++;
			}
		}
	}
	
	static class Decrement implements Runnable {
		public void run() {
			for (int i = 0; i < 10000; i++) {
				sharedData--;
			}
		}
	}
}
```

> 레이스 컨디션을 방지하면서 임계 구역을 관리하기 위해서는 프로세스와 스레드가 동기화 되어야 함

**동기화(synchronization)**
- 실행 순서 제어: 프로세스 및 스레드를 올바른 순서로 실행하기
- 상호 배제: 동시에 접근해서는 안되는 자원에 하나의 프로세스 및 스레드만 접근하기

## 3.1 동기화 기법

### 3.1.1 뮤텍스 락(mutex lock, MUTual EXclusion)
> 동시에 접근해서는 안 되는 자원에 동시 접근이 불가능하도록 상호 배제를 보장하는 동기화 도구

- 상호 배제를 위한 락(lock)
- 임계 구역에 접근하고자 한다면 반드시 락을 획득(acquire)해야 하고, 임계 구역에서의 작업이 끝났다면 락을 해제(release)해야 한다.
- 프로세스 및 스레드가 공유하는 변수(lock)와 2개의 함수(acquire, release)로 구현

- 프로세스 P1 acquire() 호출, 임계 구역 진입
- 프로세스 P2 acquire() 호출, lock을 획득하지 못해 임계 구역 접근 불가
- 프로세스 P1 임계 구역 작업 종료, release() 호출
- 프로세스 P2 임계 구역 진입

```Java
static Lock lock = new ReentrantLock();

// ...
lock.lock();
try {
	sharedData++;
} finally {
	lock.unlock();
}
```

### 3.1.2 세마포(semaphore)
> 뮤텍스 락보다 조금 더 일반화된 방식의 동기화 도구로, 공유 자원이 여러 개 있는 상황에서도 동기화 가능

- 변수 S: 사용 가능한 공유 자원의 개수를 나타내는 변수
	- 임계구역에 진입할 수 있는 프로세스의 개수
- wait() 함수: 임계 구역 진입 전 호출하는 함수
- signal() 함수: 임계 구역 진입 후 호출하는 함수

공유자원 2개, 프로세스 3개인 경우
- 프로세스 P1 wait() 호출, S를 1 감소시키면 S = 1이므로 임계 구역 진입
- 프로세스 P2 wait() 호출, S를 1 감소시키면 S = 0이므로 임계 구역 진입
- 프로세스 P3 wait() 호출, S를 1 감소시키면 S = -1이므로 대기 상태로 전환
- 프로세스 P1 임계 구역 작업 종료, signal() 호출 S를 1 증가시키면 S=0이므로 대기 상태였던 P3을 준비 상태로 전환
- 깨어난 프로세스 P3 임계 구역 진입
- 프로세스 P2 임계 구역 작업 종료, signal() 호출, S를 1 증가시키면 S = 1
- 프로세스 P3 임계 구역 작업 종료, signal() 호출, S를 1 증가시키면 S = 2

```Java
static Semaphore semaphore = new Semaphore();

// ...
try {
	semaphore.acquire();
	sharedData++;
} finally {
	lock.release();
}
```

### 3.1.3 조건변수와 모니터

**조건 변수(condition variable)**
- 실행 순서 제어를 위한 동기화 도구
- 특정 조건 하에 프로세스를 실행/일시 중단함으로써 프로세스나 스레드의 실행 순서를 제어할 수 있음
	- wait() 함수
		- 호출한 프로세스 및 스레드의 상태를 대기 상태로 전환하는 함수
	- signal() 함수
		- wait()로 일시 중지된 프로세서 및 스레드의 실행을 재개하는 함수

- 아직 특정 프로세스가 실행될 조건이 되지 않았을 때는 wait()를 통해 실행 중단
- 특정 프로세스가 실행될 조건이 충족되었을 때는 signal()을 통해 실행 재개

**모니터(monitor)**
- 공유 자원과 그 공유 자원을 다루는 함수(인터페이스)로 구성된 동기화 도구로, 상호 배제를 위한 동기화뿐만 아니라 실행 순서 제어를 위한 동기화까지 가능
	- 프로스세 및 스레드는 공유 자원에 접근하기 위해 반드시 정해진 공유 자원 연산을 통해 모니터 내로 진입해야 함
	- 모니터 안에 진입하여 실행되는 프로세스 및 스레드는 항상 하나여야 함
	- 모니터 내로 진입하여 실행 중인 프로시스 및 스레드가 있다면 큐에서 대기해야 함
- Java **synchronized** 
	- synchronized 메서드는 하나의 프로세스 및 스레드만 실행할 수 있음

### 3.1.4 스레드 안전(thread safety)
> 멀티스레드 환경에서 어떤 변수나 함수, 객체에 동시 접근이 이루어져도 실행에 문제가 없는 상태

Java Vector vs ArrayList
- Vector
	- 스레드 안정성 보장
- ArrayList
	- 스레드 안전성 보장 X

## 3.2 교착 상태(Deadlock)
> 일어나지 않을 사건을 기다리며 프로세스의 진행이 멈춰 버리는 현상

### 3.2.1 교착 상태의 발생 조건
아래의 조건 중 하나라도 만족하지 않는다면 교착 상태는 발생하지 않음
4개 조건 모두 만족할 때, 데드락이 발생할 가능성이 생김

- **상호 배제**
	- 한 번에 하나의 프로세스만 해당 자원을 이용 가능했기 때문에 발생함
	- 즉, 하나가 사용중인 프로세스를 다른 자원이 사용할 수 없는 상호배제의 상황이어야 함
- **점유와 대기**
	- 자원을 할당받은 상태(점유)에서 다른 자원 할당받기를 기다리는 상황(대기)
- **비선점**
	- 자원을 이용하는 프로세스의 작업이 끝나야만 비로소 자원을 이용할 수 있다는 것
	- 어떤 프로세스도 다른 프로세스의 자원을 강제로 뺏지 못하는 경우
- **원형 대기**
	- 프로세스와 프로세스가 요청한 자원이 원의 형태를 이루는 경우(circular dependency)

### 3.2.2 교착 상태의 해결 방법

**교착 상태 예방**
- 교착 상태를 발생시키는 4가지 필요 조건 중 하나를 충족하지 못하게 하는 방법
	- 한 프로세스에 필요한 자원 몰아주기
	- 할당 가능한 모든 자원에 번호를 매겨 순서대로 할당하기
**교착 상태 회피**
- 교착 상태를 한정된 자원의 무분별한 할당으로 인해 발생하는 문제로 간주
- 은행원 알고리즘(banker's algorithm)
**교착 상태 검출 후 회복**
- 교착 상태의 발생을 인정하고 처리하는 사후 조치
- 자원 할당 후 주기적으로 교착 상태 발생 여부 검사
- 자원 선점을 통해 회복시키거나, 프로세스를 강제 종료함으로써 회복

---
# 4. CPU 스케줄링
>다양한 프로세스와 스레드에 CPU 사용을 배분하는 방법이 CPU 스케줄링

## 4.1 우선순위

모든 프로세스가 CPU의 자원을 필요로 하기 때문에 운영체제는 공정하고 합리적인 방법으로 CPU의 자원을 프로세스에 할당해야 함. 하지만 각 프로세스의 우선순위(priority)가 다르므로, 운영체제는 프로세스별 우선순위를 PCB에 명시하고, 우선순위가 높은 프로세스에 CPU의 자원을 더 빨리, 더 많이 할당함

**CPU 활용률(CPU utilization)**
- 전체 CPU의 가동 시간 중 작업을 처리하는 시간의 비율
- 운영체제는 CPU 활용률을 높게 유지할 수 있도록 우선순위를 할당함

**CPU 버스트(CPU burst)**
- 프로세스가 CPU를 이용하는 작업
- CPU 집중 프로세스(CPU bound process)
	- CPU 작업이 많은 프로세스
	- 대기 상태보다 실행 상태에 더 많이 머무름

**입출력 버스트(I/O burst)**
- 입출력장치를 기다리는 작업
- 입출력 집중 프로세스(I/O bound process)
	- 비디오 재생과 같은 입출력 작업이 많은 프로세스
	- 실행 상태보다 입출력을 위한 대기 상태에 더 많이 머무름

> 입출력 집중 프로세스를 가능한 빨리 실행시켜 끊임없이 입출력장치를 작동시킨 다음, CPU 집중 프로세스에 집중적으로 CPU를 할당하는 것이 더 합리적

## 4.2 스케줄링 큐
> 운영체제는 프로세스들에게 자원을 이용하고 싶다면 줄을 서서 기다릴 것을 요구. 이 줄은 스케줄링 큐를 통해 구현

### 4.2.1 준비 큐와 대기 큐

**준비 큐(ready queue)**
- CPU를 이용하고 싶은 프로세스의 PCB가 서는 줄
- 실행 중인 프로세스가 할당받은 시간을 모두 소모할 경우(타이머 인터럽트) 준비 큐로 이동

**대기 큐(waiting queue)**
- 대기 상태에 접어든 프로세스의 PCB가 서는 줄
- 입출력 작업 수행 중인 경우, 대기 큐에서 대기 상태로 입출력 완료 인터럽트를 기다림
- 같은 입출력장치를 요구한 프로세스는 같은 대기 큐에서 기다림

### 4.2.2 선점형 스케줄링과 비선점형 스케줄링

**프로세스가 종료되지 않았음에도 실행 도중 스케줄링이 수행되는 시점**
1. 실행 상태에서 입출력 작업을 위해 대기 상태로 전환
2. 실행 상태에서 타이머 인터럽트가 발생

**선점형 스케줄링(preemptive scheduling)**
- 1,2 번 모든 상황에서 수행되는 스케줄링 유형
- 어떤 프로세스가 CPU를 할당 받아 사용하고 있더라도 운영체제가 프로세스로부터 CPU 자원을 **강제로 빼앗아 다른 프로세스에 할당**할 수 있는 스케줄링
- 한 프로세스의 CPU 독점을 막고 골고루 CPU 자원 분산 가능
- 문맥 교환  과정에서 오버헤드 발생 가능

**비선점형 스케줄링(non-preemptive scheduling)**
- 1번 상황에서만 수행되는 스케줄링 유형
- 어떤 프로세스가 CPU를 사용하고 있을 때 그 프로세스가 종료되거나 스스로 대기 상태에 접어들기 전까지는 다른 프로세스가 끼어들 수 없는 스케줄링 방식
- 오버헤드 발생 가능성이 적음
- 당장 CPU를 사용해야 하는 프로세스라도 기다려야 함

## 4.3 CPU 스케줄링 알고리즘
### 4.3.1 선입 선처리 스케줄링(FCFS, First Come First Served)

 - 준비 큐에 삽입된 순서대로 먼저 CPU를 요청한 프로세스부터 CPU 할당
 - 프로세스 대기 시간이 길어질 수 있음
	 - 호위 효과(convoy effect)
		 - 먼저 삽입된 프로세스로 인해 나중에 삽입된 프로세스의 실행이 지연되는 문제

### 4.3.2 최단 작업 우선 스케줄링(SJF, Shortest Job First)

- 준비 큐에 삽입된 프로세스 중 CPU를 이용하는 시간의 길이가 가장 짧은 프로세스부터 먼저 실행
- 비선점형 스케줄링 알고리즘

### 4.3.3 라운드 로빈 스케줄링(RR, Round Robin)

- FCFS에 타임 슬라이스 개념이 더해진 스케줄링 방식
- 타임 슬라이스(time slice)
	- 프로세스가 CPU를 사용하도록 정해진 시간

### 4.3.4 최소 잔여 시간 우선 스케줄링(SRT, Shortest Remaining Time)

- 최단 작업 우선 스케줄링(SJF) + 라운드 로빈
- 정해진 타임 슬라이스만큼 CPU를 이용하되, 남아 있는 작업시간이 가장 적은 프로세스를 다음으로 CPU를 이용할 프로세스로 선택

### 4.3.5 우선순위 스케줄링

- 프로세스에 우선순위를 부여하고, 가장 높은 우선순위를 가진 프로세스부터 실행
- **아사, 기아(starvation) 현상 발생 가능**
	- 우선순위가 높은 프로세스로 인해 낮은 프로세스가 계속 연기될 수 있음
	- 에이징(aging)
		- 오랫동안 대기한 프로세스의 우선순위를 점차 높이는 방식

### 4.3.6 다단계 큐 스케줄링(multilevel queue)

- 우선순위 스케줄링이 발전된 형태
- 우선순위별로 여러 개의 준비 큐를 사용
- 프로세스들이 큐 사이를 이동할 수 없어 우선순위가 낮은 프로세스의 작업이 계속해서 연기될 수 있음

### 4.3.7 다단계 피드백 큐 스케줄링(multilevel feedback queue)

- 다단계 큐 스케줄링과 유사하나, 프로세스들이 큐 사이를 이동할 수 있음
- 타임 슬라이스 동안 실행되고 끝나지 않으면 다음 우선순위 큐에 삽입
	- 오래 CPU를 사용해야 하는 프로세스의 우선순위가 점차 낮아지게됨
	- CPU 집중 프로세스의 우선순위가 낮아지게 됨

## 4.4 리눅스 CPU 스케줄링

**리눅스 스케줄링 정책**

| 스케줄링 정책      | 적용 상황                                          |
| ------------ | ---------------------------------------------- |
| SCHED_FIFO   | 실시간성 프로세스에 적용되는 정책<br>(매우 높은 우선순위를 할당함)        |
| SCHED_RR     |                                                |
| SCHED_NORMAL | 일반적인 프로세스에 적용되는 정책                             |
| SCHED_BATCH  | 일반적인 프로세스만큼 자주 선점하지 않는 배치 작업에 적용되는 정책          |
| SCHED_IDLE   | 우선순위가 매우 낮은 프로세스에 적용되는 정책<br>(매우 낮은 우선순위를 할당함) |
### 4.4.1 SCHED_NORMAL
- 일반적인 프로세스에 적용되는 스케줄링 정책
- CFS(Completely Fair Scheudler) 스케줄러에 의해 스케줄링
	- 완전히 공평한 CPU 시간 배분을 지향
	- 리눅스는 프로세스마다 가상 실행시간(vruntime) 정보를 유지함
		- 실제로 실행된 시간이 아닌 프로세스의 가중치(weight)를 고려한 가상의 실행 시간
		- 프로세스 우선순위가 높아질수록 가중치도 높아짐
$$
		vurntime = CPU를 할당받아 실행된 시간 * \frac{평균 가중치(상수)}{프로세스의 가중치}
$$
- CFS는 vruntime이 가장 작은 프로세스부터 스케줄링
- CFS로 스케줄링되는 프로세스들의 타임슬라이스는 프로세스의 가중치에 따라 결정
	- 프로세스의 가중치가 높아지면 타임 슬라이스도 크게 할당받을 수 있음
$$
	타임 슬라이스 = \frac{프로세스의 가중치}{CFS 큐에서 대기하는 프로세스들의 전체 가중치} * CFS 큐에서 대기하는 프로세스들의 타임 슬라이스 전체 합
$$


- vruntime과 가중치는 /proc/\<PID\>/sched 파일을 출력하면 확인할 수 있음
- 커널은 가장 작은 vruntime 프로세스 선별을 위해 RB 트리 사용

---
# 5. 가상 메모리

> CPU와 프로세스는 메모리 몇 번지에 무엇이 저장되어 있는지까지 다 일일이 알고 있지 않음. CPU 내부 저장공간(레지스터)이 메모리만큼 크지 않기 때문

- 새로운 프로세스는 새롭게 메모리에 적재
- 사용되지 않는 프로세스는 메모리에서 삭제

## 5.1 물리 주소와 논리 주소

**물리 주소(physical address)**
- 메모리의 하드웨어 상 실제 주소

**논리 주소(logical address)**
- 프로세스마다 부여되는 0번지 부터 시작하는 주소 체계
- CPU와 프로세스가 사용하는 주소 체계
- **중복**되는 논리 주소의 번지 수는 얼마든지 존재할 수 있음

**메모리 관리 장치(MMU, Memory Management Unit)**
- 실제 정보가 저장되어 있는 하드웨어 상의 메모리와 상호작용을 위해서는 주소 변환이 필요함
- CPU가 이해하는 논리 주소를 메모리가 이해하는 물리 주소로 변환

## 5.2 스와핑과 연속 메모리 할당
### 5.2.1 스와핑(swapping)
 메모리에 적재된 프로세스들 중 현재 실행되고 있지 않은 프로세스가 존재할 수 있음. 입출력 작업을 요구하며 대기 상태가 되었거나 오랫동안 사용되지 않은 프로세스가 이러하며, 이런 프로세스들은 임시로 **스왑 영역(swap space)** 라는 보조기억장치 일부의 영역으로 쫓아냄

**스왑 아웃(swap-out)**
- 메모리 -> 스왑 영역
**스왑 인(swap-in)**
- 스왑 영역 -> 메모리

### 5.2.2 연속 메모리 할당과 외부 단편화

**연속 메모리 할당**
- 프로세스에 연속적인 메모리 공간을 할당하는 방식

**외부 단편화(external fragmentation)**
- 프로세스들이 메모리에 연속적으로 할당되는 환경에서, 메모리 사이 사이에 빈 공간이 생김에 따라 프로세스 바깥에 생긴 빈 공간들보다 큰 프로세스를 적재하기 어려운 상황이 만들어짐 > 메모리 낭비

## 5.3 페이징을 통한 가상 메모리 관리
> 스와핑과 연속 메모리 할당은 **외부 단편화**와 **물리 메모리보다 큰 프로세스를 실행할 수 없다**는 문제가 있음. 이러한 문제를 해결하기 위해 운영체제는 가상 메모리(virtual memory) 기술을 사용함

**가상 메모리(virtual memory)**
- 실행하고자 하는 프로그램의 일부만 메모리에 적재해, 실제 메모리보다 더 큰 프로세스를 실행할 수 있도록 만드는 메모리 관리 기법





---
# 6. 파일 시스템
