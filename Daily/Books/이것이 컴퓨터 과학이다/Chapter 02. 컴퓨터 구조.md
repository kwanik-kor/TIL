# 1. 컴퓨터 구조의 큰 그림

## 1.1 컴퓨터가 이해하는 정보

**데이터**
- 숫자, 문자, 이미지, 동영상과 같은 정적인 정보
- 명령어에 종속적인 정보, 명령의 대상, 명령어의 재료

**명령어**
- 수행할 동작과 수행할 대상으로 구성
- CPU: 명령어를 이해하고 실행하는 주체
	- CPU의 종류에 따라 실행 가능한 세부적인 명령어의 종류와 처리의 양상이 달라질 수 있음

## 1.2 컴퓨터의 핵심 부품

**CPU(중앙처리장치)**
- 정보를 읽어 들이고, 해석하고, 실행하는 부품
- 

**메모리(주기억장치)**

**캐시 메모리**

**보조기억장치**

**입출력장치**

---
# 2. 컴퓨터가 이해하는 정보
> 0과 1만 이해하는 컴퓨터가 문자와 숫자를 인식하는 방법, 표현된 정적인 데이터가 명령어에 대해 어떻게 실행되는지

- 비트(bit): 정보를 표현하는 가장 작은 단위
- 워드(word): CPU 관점에서의 정보 단위로, CPU가 한 번에 처리할 수 있는 데이터의 크기
	- CPU가 한 번에 32비트를 처리할 수 있다면 1워드 = 32비트

## 2.1 데이터 - 0과 1로 숫자 표현하기

- CPU는 0과 1만 이해할 수 있으며 컴퓨터는 2진법을 사용
- **소수 표현**
	- 표현하고자 하는 소수와 실제로 저장된 소수 간의 오차가 발생할 수 있음
	- **부동 소수점(IEEE 754)**
		- 필요에 따라 소수점의 위치가 이동할 수 있음
		- m x 2^n
			- m : 가수(significant)
			- n : 지수(exponent)
		- 부호 비트 + 지수 비트 + 가수 비트
			- 32 비트 : 1 + 8 + 23
			- 64 비트 : 1 + 11 + 52
		- 가수는 1.XXX 형태로 1로 **정규화한 수를 저장**
		- 1.1010111010101 x 2^6
			- 지수 : 바이어스(bias) + 6
				- **바이어스**: 2^(k - 1) - 1
			- 가수 : 1010111010101 저장
```Java
var a = 0.1;  
var b = 0.2;  
var c = 0.3;  
  
if (a + b == c) {  
    System.out.println("equal");  
} else {
	// here works!
    System.out.println("not equal");  
}
```

## 2.2 데이터 - 0과 1로 문자 표현하기

- 문자 집합(Character set): 컴퓨터가 이해할 수 있는 문자들의 집합
	- 문자 인코딩(Character Encoding): 문자 집합 속 문자를 0과 1로 이루어진 문자 코드로 변환하는 과정
	- 문자 디코딩(Character Decoding): 0과 1로 표현된 문자를 사람이 이해하는 문자로 변환하는 과정

- **ASCII(American Standard Code for Information Interchange)**
	- 영어, 알파벳, 아라비아 숫자, 일부 특수문자
	- 8비트(1 Byte)
		- 그 중 1 비트는 **패리티 비트**로 오류 검출용 비트
		- 실질적으로는 7비트로써 128개의 문자 표현
	- 코드 포인트(Code Point)
		- 글자에 부여된 고유한 값
		- A : 65
		- a : 97
	- 한글 표현 X

- **EUC-KR**
	- 아스키 문자 : 1 바이트
	- 하나의 한글 글자 : 2 바이트
		- 네 자리 16진수로 표현
	- ex1) 한 : c7d1
	- ex2) 글 : b1db
	- 일부 한글 문자 표현할 수 없음
	- 글자에 부여된 값을 그대로 인코딩 값으로 사용

- **유니코드(Unicode)**
	- 훨씬 많은 언어, 특수문자, 화살표, 이모티콘까지 표현할 수 있는 통일된 문자 집합
		- ex1) 한: 0xd55c
		- ex2) 글: 0xae00
	- 인코딩 방법 존재
		- 가변 길이 인코딩
			- 인코딩된 결과의 길이가 일정하지 않을 수 있음
			- UTF-8
			- UTF-16
			- UTF-32
		- base64
			- 이진 데이터까지 변환할 수 있는 인코딩 방식
			- 64진법
			- 변환할 데이터를 6비트씩 나누어 4개씩(24비트씩) 한번에 변환
			- 나누어 떨어지지 않는 자리는 0으로 채워 패딩(padding)이 되고 =으로 표기

## 2.3 명령어

- 명령어 : **수행할 동작**과 **수행할 대상**으로 구성
	- **연산 코드(opcode)** : 수행할 동작
		- CPU에 따라 연산코드의 구체적인 생김새가 다르지만, 공통적인 유형 존재
	- **오퍼랜드(operand)** : 수행할 대상
		- 데이터 자체
		- 데이터가 저장된 위치
			- 대부분 데이터가 저장된 위치(메모리 주소, 레지스터 이름)가 명시됨
			- 주소 필드(address field)라고도 부름

- 대표적인 연산코드 유형

| 유형       | 연산코드                         | 설명                               |
| -------- | ---------------------------- | -------------------------------- |
| 데이터 전송   | MOVE                         | 데이터를 옮겨라                         |
|          | STORE                        | 메모리에 저장해라                        |
|          | LOAD(FETCH)                  | 데이터를 메모리에서 CPU로 가져와라             |
|          | PUSH                         | 데이터를 스택에 저장하라                    |
|          | POP                          | 스택의 최상단 데이터를 가져와라                |
| 산술/논리 연산 | ADD/SUBTRACT/MULTIPLY/DIVIDE | 덧셈/뺄셈/곱셈/나눗셈을 수행하라               |
|          | INCREMENT/DECREMENT          | 오퍼랜드에 1을 더해라<br>오퍼랜드에서 1을 빼라     |
|          | AND/OR/NOT                   | AND/OR/NOT 연산을 수행해라              |
|          | COMPARE                      | 두 개의 숫자, 혹은 true/false를 비교해라     |
| 제어 흐름 변경 | JUMP                         | 특정 주소로 실행 순서를 옮겨라                |
|          | CONDITIONAL JUMP             | 조건에 부합할 경우 특정 주소로 실행 순서를 옮겨라     |
|          | HALT                         | 프로그램의 실행을 멈춰라                    |
|          | CALL                         | 되돌아올 주소를 저장한 채 특정 주소로 실행 순서를 옮겨라 |
|          | RETURN                       | CALL을 호출할 때 저장했던 주소로 돌아가라        |
| 입출력 제어   | READ(INPUT)                  | 특정 입출력장치로부터 데이터를 읽어라             |
|          | WRITE(OUTPUT)                | 특정 입출력장치로 데이터를 써라                |
|          | START IO                     | 입출력장치를 시작해라                      |
|          | TEST IO                      | 입출력장치의 현재 상태를 확인해라               |

- 기계어(machine code)
	- CPU가 이해할 수 있도록 0과 1로 표현된 정보를 있는 그대로 표현한 언어
- 어셈블리어(assembly language)
	- 0과 1로 표현된 기계어를 읽기 편한 형태로 단순 번역한 언어

- **명령어 사이클(instruction cycle)**
	- CPU가 명령어를 처리하는 과정에는 정형화된 흐름이 있으며, 이 흐름 속에서 프로그램 속 각각의 명령어들은 일정한 주기를 반복하며 실행되는데, 이 주기를 명령어 사이클이라 함
	- **인출 사이클(fetch cycle)**
		- 첫 번째 과정
		- 메모리에 있는 명령어를 CPU로 가져옴
	- **실행 사이클(execution cycle)**
		- CPU로 가져온 명령어를 실행하는 단계
	- **간접 사이클(indirect cycle)**
		- 명령어를 실행하기 위해 한 번 더 메모리에 접근하는 단계
	- **인터럽트 사이클(interrupt cycle)**
		- 

---
# 3. CPU

## 3.1 레지스터

> CPU 안에 있는 작은 임시 저장장치

대부분의 CPU가 공통적으로 포함하고 있는 대표적인 주요 레지스터

- **프로그램 카운터(PC, Program Counter)**
	- 메모리에서 다음으로 읽어 들일 명령어의 주소를 저장
	- 명령어 포인터(IR, Instruction Pointer)
	- 일반적으로 카운터를 1씩 증가시키나, CONDITIONAL JUMP와 같은 명령어에 의해 임의의 위치로 변경되기도 함
- **명령어 레지스터(IR, Instruction Register)**
	- 메모리에서 방금 읽어들인, **해석할 명령어**를 저장
	- 제어장치는 IR의 명령어를 해석하여, ALU로 연산시키거나, 다른 부품으로 제어 신호를 보냄
- **범용 레지스터(general purpose register)**
	- 데이터, 명령어, 주소 모두를 저장할 수 있는 보편적인 레지스터
- **플래그 레지스터(flag register)**
	- 연산의 결과 혹은 CPU 상태에 대한 부가 정보인 플래그 값을 저장
	- 종류
		- 부호 플래그 : 연산 결과의 부호(1: 음수, 0: 양수)
		- 제로 플래그 : 연산 결과가 0인가(1: 0, 0: X)
		- 캐리 플래그 : 연산 결과에 올림수나 빌림수가 발생했는지 여부
		- 오버플로우 플래그 : 오버플로우 발생 여부
		- 인터럽트 플래그 : 인터럽트가 가능한지의 여부
		- 슈퍼바이저 플래그 : 커널 모드로 실행 중인지, 사용자 모드로 실행중인지의 여부
- **스택 포인터(stack pointer)**
	- 메모리 내 스택 영역의 최상단 스택 데이터 위치를 가리키는 특별한 레지스터

## 3.2 인터럽트(interrupt)

> CPU의 작업을 방해하는 신호

### 3.2.1 동기 인터럽트(synchronous interrupt)

>CPU에 의해 발생하는 인터럽트, 예외(exception)

**폴트(fault)**
- 예외가 발생한 명령어부터 실행을 재개하는 것
- 페이지 폴트

**트랩(trap)**
- 예외가 발생한 명령어의 다음 명령어부터 실행을 재개하는 것
- ex) 디버깅

**중단(abort)**
- 심각한 오류로 인한 프로그램 강제 중단

**소프트웨어 인터럽트(software interrupt)**
- 시스템 콜이 발생했을 때 발생하는 예외

### 3.2.2 비동기 인터럽트(asynchronous interrupt)

> 입출력장치에 의해 발생하는 인터럽트, 알림의 역할, 하드웨어 인터럽트

- 효율적으로 명령어를 처리하기 위함
- 입출력장치와 CPU의 속도 차이로 인해 주기적으로 폴링을 할 경우 비효율적

- 입출력장치 -> CPU **인터럽트 요청 신호** 전송
- CPU는 실행 사이클이 끝나고 명령어를 인출하기 전에 인터럽트 여부 확인
- CPU는 인터럽트 요청을 확인하고, **인터럽트 플래그**를 통해 인터럽트 수용 가능 여부 확인
- 받아들일 수 있다면 현재까지의 작업을 백업
- CPU는 **인터럽트 벡터**를 참조하여 **인터럽트 서비스 루틴** 실행
- 인터럽트 서비스 루틴이 끝나면 백업 복구하여 실행

**인터럽트 플래그**
- 불가능으로 설정되어 있다 하더라도 무시할 수 없는 요청도 있음
- **막을 수 있는 인터럽트(maskable interrupt)**
- **막을 수 없는 인터럽트(NMI, non maskable interrupt)**

**인터럽트 서비스 루틴**
- 인터럽트가 발생했을 때 해당 인터럽트를 어떻게 처리하고 작동해야 할지에 대한 정보로 이루어짐
- 인터럽트 핸들러(interrupt handler)

**인터럽트 벡터(interrupt vector)**
- 인터럽트 서비스 루틴을 식별하기 위한 정보
- CPU는 하드웨어 인터럽트 요청을 보낸 대상으로부터 버스를 통해 인터럽트 벡터를 전달받음

**백업**
- 끝나면 원래 하던 작업으로 돌아와 실행해야 하므로 수행
- 현재 프로그램을 재개하기 위해 필요한 모든 내용을 메모리 내 **스택**에 백업

## 3.3 CPU 성능 향상을 위한 설계
### 3.3.1. CPU 클럭 속도
- 클럭(clock) : 컴퓨터의 부품을 일사분란하게 움직일 수 있게 하는 시간의 단위
- 클럭 속도 : 헤르츠(Hz), 1초에 클럭이 몇 번 반복되는지
	- CPU의 속도 단위로 간주되기도 함

### 3.3.2 멀티코어와 멀티스레드

**코어(core)**
- CPU 내에서 명령어를 읽어 들이고, 해석하고, 실행하는 부품
	- 고전적으로는 위 정의를 CPU로 보았으나, CPU 안에 해당 부품이 여러 개가 존재할 수 있게 됨
- 멀티코어 CPU, 멀티코어 프로세서 : 복수의 코어를 포함하는 CPU

**스레드(Thread)**
- 하나의 코어가 동시에 처리하는 명령어의 단위
	- SW적인 스레드와 다름
- 멀티스레드 프로세서, 멀티스레드 CPU : 하나의 코어로 여러 명령어를 동시에 처리하는 CPU
- **논리 프로세서(logical processor)**
- **병렬성(parallelism)**
	- 작업을 물리적으로 동시에 처리하는 성질
	- 동시성(concurrency)과는 다름
		- 동시에 작업을 처리하는 것 처럼 보이는 성질

## 3.4 파이프라이닝을 통한 명령어 병렬 처리

> **명령어 병렬 처리 기법(ILP, Instruction-Level Parallelism)** 은 여러 명령어를 동시에 처리하여 CPU를 한시도 쉬지 않고 작동시킴으로써 CPU의 성능을 높이는 기법

명령어 파이프라이닝
- 명령어 인출(Instruction Fetch)
- 명령어 해석(Instruction Decode)
- 명령어 실행(Execute Instruction)
- 결과 저장(Write Back)

단계만 겹치지 않는다면 CPU가 각각의 단계를 동시에 실행할 수 있음
- 인출되는 동안 실행
- 실행되는 동안 저장

**슈퍼스칼라(superscala)**
- CPU 내부에 여러 명령어 파이프라인을 포함하는 구조

명령어 집합은 CPU마다 다를 수 있음
- **CISC(Complex Instruction Set Computer)**
	- 다채로운 기능을 지원하는 복잡한 명령어로 구성된 집합
	- 인텔 x86, x86-64
	- 명령어 크기 및 실행되기까지 시간이 일정하지 않고 하나의 실행에 여러 클럭 주기가 필요함
- **RISC(Reduced Instruction Set Computer)**
	- CISC에 비해 명령어가 적으나, 1 클럭 내외로 실행되는 짧고 규격화된 명령어 집합
	- 애플 M1 CPU
	- CISC에 비해 크기가 규격화되어 있고 1클럭 내외임에 따라 파이프라이닝에 최적화되어 있음

**파이프라인 위험(pipeline hazard)**
- 파이프라이닝이 실패하여 성능 향상이 이루어지지 않는 상황
- **데이터 위험(data hazard)**
	- 명령어 간의 데이터 의존성에 의해 발생
- **제어 위험(control hazard)**
	- 프로그램 카운터의 갑작스러운 변화에 의해 발생
- **구조적 위험(structural hazard)**
	- 서로 다른 명령어가 동시에 ALU, 레지스터 등 같은 CPU 부품을 사용하려고 하는 경우
	- 자원 위험(resource hazard)

---

# 4. 메모리

## 4.1 RAM(Random Access Memory)
> 메인 메모리의 역할을 하는 RAM과 ROM, 그 중 RAM을 보통 메인 메모리로 지칭한다.

- **휘발성 저장장치(volatile memory)**
	- 전원이 공급되지 않으면 저장하고 있던 데이터와 명령어가 날라감
	- <-> 비휘발성 저장장치(non-volatile memory) : 보조기억장치
- CPU가 보조기억장치에 저장된 프로그램을 곧장 가져와 실행할 수 없으므로 메모리로 복사해와야 함
	- RAM이 크면 많은 데이터를 가져와 미리 저장해둘 수 있음
- **임의 접근**: 저장된 요소에 순차적으로 접근하지 않고 임의의 위치에 곧장 접근 가능한 방식
	- 직접 접근(direct access)
	- <-> 순차 접근(sequential access)

- **DRAM(Dynamic RAM)**\
	- 시간이 지나면 데이터가 동적으로 점차 사라지는 RAM
	- 데이터 소멸을 막기 위해 일정 주기로 재활성화(다시 저장)
	- 소비 전력이 낮고, 저렴하며, 집적도가 높아 일반적으로 메모리로 사용함
- **SRAM(Static RAM)**
	- 시간이 지나도 저장된 데이터가 사라지지 않는 RAM
	- 전원 공급이 꺼지면 소실되는건 마찬가지
	- 캐시 메모리
	- 속도는 빠르지만 DRAM에 비해 전력도 크고, 비싸고 집적도가 낮음
- **SDRAM(Synchronous Dynamic RAM)**
	- 클럭 신호와 동기화된 발전된 형태의 DRAM
	- 클럭에 맞춰 CPU와 정보를 주고받을 수 있음
- **DDR SDRAM(Double Data Rate SDRAM)**
	- 대역폭을 넓혀 속도를 빠르게 만든 SDRAM
	- SDRAM에 비해 전송 속도가 두 배 가량 빠름
	- 최근엔 DDR4 SDRAM이 일반적이며 SDRAM의 16배 넓은 대역폭을 가짐

## 4.2 메모리에 바이트를 밀어 넣는 순서 - 빅 엔디안과 리틀 엔디안

- 현대의 메모리는 대부분 데이터를 Byte 단위로 저장하고 관리
- CPU로부터 바이트 단위가 아닌 4바이트 / 8바이트 단위의 워드 단위로 받아들임

**바이트를 어떤 순서로 저장할 것인가**
- **빅 엔디안(big endian)**
	- 낮은 번지의 주소에 상위 바이트(MSB, Most Significant Bit)부터 저장
	- 메모리 값을 직접 읽거나, 디버깅할 때 용이
- **리틀 엔디안(little endian)**
	- 낮은 번지의 주소에 하위 바이트(LSB, Least Significant Bit)부터 저장
	- 직접 읽고 쓰기는 불편하나, 연산에 용이

## 4.3 캐시 메모리(cache memory)
> CPU가 메모리에 접근하는 속도는 CPU가 레지스터에 접근하는 속도보다 느리기 때문에 CPU의 연산속도와 메모리 접근 속도의 차이를 보완하기 위한 것이 **캐시 메모리**

- CPU의 연산 속도와 메모리 접근 속도의 차이를 줄이기 위해 탄생한 저장장치
- SRAM
- L1, L2, L3
	- L1 쪽으로 갈수록 코어에 가까움
	- 일반적으로 L1, L2 캐시는 코어 내부, L3 캐시는 코어 외부에 위치
	- 메모리 크기 : L1 < L2 < L3
	- 속도 : L1 > L2 > L3
	- 멀티코어 프로세서의 경우 각 코어마다 L1, L2는 고유한 캐시로 할당, L3는 공유하는 형태로 구성
	- L1은 명령어만 저장하는 L1I, 데이터만 저장하는 L1D 로 구분하기도 함
		- **분리형 캐시(split cache)**

**캐시 히트와 캐시 미스**
- **캐시 히트(cache hit)**
	- 캐시 메모리가 예측하여 저장한 데이터가 CPU에 의해 실제로 사용되는 경우
- 캐시 미스(cache miss)
	- 예측 실패로 CPU가 메모리로부터 직접 가져와야 하는 경우
- **캐시 적중률(cache hit rate)**
	- 캐시 히트 횟수 / (캐시 히트 횟수 + 캐시 미스 횟수)

**참조 지역성의 원리(locality of reference, principle of locality)**
- 시간 지역성 : CPU는 최근에 접근했던 메모리 공간에 다시 접근하려는 경향이 있음
	- **변수**, 프로그램 실행되는 동안 여러 번 사용되기 때문
- 공간 지역성 : CPU는 접근한 메모리 공간의 근처에 접근하려는 경향이 있음
	- **배열**, 배열에 순차 접근하는 것과 그렇지 않은 것에는 성능 차이가 있음

**캐시 메모리의 쓰기 정책과 일관성**
- 캐시 메모리에 데이터를 쓸 때는 캐시 메모리에 새롭게 쓰여진 데이터와 메모리 상의 데이터가 일관성을 유지해야 함
- **즉시 쓰기(write-through)**
	- 캐시 메모리와 메모리에 동시에 쓰는 방법
	- 일관성 방지는 가능하나, 메모리 접근을 최소화하기 위해 만든 캐시 메모리의 효율이 떨어질 수 있음
- **지연 쓰기(write-back)**
	- 수정된 데이터를 한 번에 메모리에 반영
	- 속도는 빠르지만, 일관성이 깨질 수 있는 위험이 있음
- 다른 코어가 사용하는 캐시 메모리와의 불일치도 발생할 수 있음
	- **캐시 일관성 프로토콜**

---
# 5. 보조기억장치와 입출력장치

> 보조기억장치는 메모리의 휘발성을 보완하는 동시에, 메모리보다 큰 저장 공간을 제공함

**하드 디스크 드라이브(HDD, Hard Disk Drive)**
- 자기적인 방식으로 데이터를 읽고 쓰는 보조기억장치
- 뾰족한 리더기인 헤드를 통해 플래터에 저장된 데이터에 접근

**플래시 메모리(flash memory)**
- 전기적인 방식으로 데이터를 읽고 쓰는 반도체 기반의 저장장치
- USB, SD 카드, SSD
- 보조기억장치로는 SSD(Solid-State Drive)를 주로 사용

## 5.1 RAID(Redundant Array of Independent Disks)
> 보조기억장치에 저장된 정보를 안정적이고 안전하게 관리하는 방법
> 데이터의 안전성 혹은 성능을 확보하기 위해 여러 개의 독립적인 보조기억장치를 마치 하나의 보조기억장치처럼 사용하는 기술

- 전원이 꺼져도 데이터를 안전하게 보관해야 함
- CPU가 필요로 하는 정보를 조금이라도 빠른 성능으로 메모리에 전달해야 함

### 5.1.1 RAID0
- 데이터를 여러 보조기억장치에 **단순하게 나누어 저장하는 구성 방식**
- 저장되는 데이터를 하드디스크의 개수만큼 나누어 저장
	- 스트라입(Stripe) : 줄무늬처럼 분산되어 저장된 데이터
	- 스트라이핑(Striping) : 분산하여 저장하는 동작
- 장점
	- 빠른 입출력 속도
		- 데이터를 한 번에 동시에 읽고 쓸 수 있기 때문
- 단점
	- 저장된 데이터가 안전하지 않음
		- 1번에 문제가 생기면, 2, 3, 4번에 저장된 데이터는 불완전해짐

### 5.1.2 RAID1
- 완전한 복사본을 만들어 저장하는 구성 방식
- 미러링(mirroring)
- 장점
	- 복구가 간단하고 안정성이 높음
- 단점
	- RAID0보다 쓰기 속도가 느려짐
	- 복사본이 저장된 크기만큼 사용가능한 용량이 줄어듬

### 5.1.3 RAID4
- **패리티 정보를 저장하는 디스크**를 따로 두는 구성 방식
- 장점
	- 별도의 패리티 정보용 디스크로 RAID1에 비해 비교적 적은 하드 디스크를 사용할 수 있음
- 단점
	- 패리티를 저장하는 장치에 병목 현상이 발생

### 5.1.4 RAID5
- 패리티를 분산하여 저장하는 구성 방식
- RAID4의 병목 현상을 보완할 수 있음

### 5.1.5 RAID6
- RAID5와 구성이 동일하지만, 서로 다른 2개의 패리티를 두는 구성 방식
- 오류를 검출하고 복구할 수 있는 수단이 2개 생김
- 두 개의 패리티 비트를 저장해야 함에 따라 RAID5에 비해 쓰기 속도는 일반적으로 느림

### 5.1.6 Nested RAID
- 여러 RAID 레벨을 혼합한 방식
- RAID10 : RAID0 + RAID1
- RAID50 : RAID5 + RAID0

## 5.2 입출력 기법
> 보조기억장치는 결국 메모리를 보조하는 임무를 수행하는 특별한 입출력장치

### 5.2.1 장치 컨트롤러와 장치 드라이버
>제조사마다 다양한 규격과 작동 방식이 있기에, 입출력장치는 CPU와 직접 연결되어 정보를 주고 받지 않음

**장치 컨트롤러(Device Controller)**
- CPU와 입출력장치 사이의 통신을 중개하는 중개자 역할의 하드웨어
- 장치 컨트롤러의 중개를 통해 입출력장치 작동
- RAM과 같은 저장장치 존재
	- CPU와 정보를 주고 받는 과정에서 기억해야 하는 많은 중간 값들을 저장

**장치 드라이버(Device Driver)**
- CPU가 장치 컨트롤러와 상호작용함으로써 입출력장치를 작동시키는 과정 역시 프로그램을 통해 이루어짐
- 장치 컨트롤러의 동작을 알고, 장치 컨트롤러가 컴퓨터 내부와 정보를 주고받을 수 있도록 하는 프로그램


### 5.2.2 CPU와 장비 컨트롤러가 정보를 주고 받는 방법

**프로그램 입출력(Program I/O)**
- 프로그램 속 명령어로 입출력 작업 수행
- 입출력 명령어를 실행함으로써 장치 컨트롤러와 상호작용
	- '하드 디스크 컨트롤러에 10을 써라'
- **고립형 입출력(isolated I/O)**
	- 입출력장치에 접근하는 주소와 메모리에 접근하는 주소를 별도의 주소 공간으로 간주
	- 별도의 입출력 명령어 필요
- **메모리 맵 입출력(memory mapped I/O)**
	- 입출력장치에 접근하는 주소 공간과 메모리에 접근하는 주소 공간을 구분하지 않고 메모리의 일부 사용
	- 별도의 입출력 명령어 필요X
	- 메모리에 접근하는 명령어로 입출력 가능

**인터럽트 기반 입출력: 다중 인터럽트**
- 우선순위가 높은 인터럽트가 우선적으로 처리되는 경우가 일반적
- 플래그 레지스터 속 인터럽트 비트가 활성화되어 있는 경우, 혹은 인터럽트 비트를 비활성화해도 무시할 수 없는 인터럽트인 NMI(Non-Maskable Interrupt)가 발생한 경우, 먼저 처리하게 됨
- **프로그래머블 인터럽트 컨트롤러(PIC, Programmable Interrupt Controller)**
	- 다중 인터럽트를 처리하기 위함
	- 장치 컨트롤러에서 보낸 하드웨어 인터럽트 요청들의 우선순위 판별, CPU에게 알려줌
	- NMI까지 우선순위를 판단하지는 않음
	- 많은 하드웨어 인터럽트를 관리하기 위해 2개 이상의 계층으로 구성

> 위 두 방식은 CPU가 입출력장치와 메모리 간의 데이터 이동을 주도해야 하며, 데이터 역시 CPU를 거침
> 이로 인해 CPU의 부담이 커짐

**DMA(Direct Memory Access) 입출력**
> CPU를 거치지 않고도 입출력장치와 메모리가 상호작용할 수 있는 방식

- 직접 메모리에 접근할 수 있는 입출력 기능
- DMA 컨트롤러
	- 시스템 버스에 연결
	- 입출력장치들은 입출력 버스라는 입출력장치 컨트롤러의 전용 버스와 연결
	- 과정
		- CPU가 DMA 컨트롤러에게 입출력장치의 주소, 연산, 메모리 주소 등 정보와 함께 입출력 작업 명령
		- DMA 컨트롤러가 CPU 대신 장치 컨트롤러와 상호작용하며 입출력 장치 수행
		- 작업이 끝나면 CPU에게 인터럽트를 걸어 완료를 알림
	- **사이클 스틸링(cycle stealing)**
		- 시스템 버스는 동시 사용이 불가능함
		- DMA 컨트롤러는 시스템 버스를 통해 메모리 접근을 하지만, 이 동안은 CPU가 시스템 버스를 사용할 수 없음
		- DMA 컨트롤러는 CPU가 사용하지 않을 때마다 조금씩 사용하거나 CPU가 양보하게 됨
		- CPU 입장에선 도둑 맞는 기분!
- **PCIe(Peripheral Component Interconnect express)**
	- 대표적 입출력 버스
	- 다양한 입출력장치 연결
	- PCIe 버전에 따라 최대 속도가 달라짐
	- PCIe 버스가 **여러 레인(lane)**을 이용해 정보를 주고받을 수 있음
		- 레인 : 버스를 통해 정보를 송수신하는 단위
		- 레인의 수가 2개, 4개, 8개가 되면 한 번에 통신을 주고 받을 수 있는 양도 늘어남

---
# GPU(Graphic Processing Unit)
> 화면에 그림을 그리는 등 대량의 그래픽 연산을 위해 탄생한 장치

- 딥러닝 연산, 가상화폐 채굴 등 다양한 분야에 대한 연산이 가능해짐
	- **GPGPU(General-Purpose computing on Graphics Processing Units)**
		- 범용적인 목적의 GPU 사용기술
- 개별 코어의 성능은 CPU보다 떨어지지만, 수백 개에서 수천 개의 코어가 포함되어 있음
	- CPU에 비해 느리며, 복잡한 기능을 제공하지 않음
	- CPU는 메모리 접근을 가급적 최소화 하고자 하나, GPU는 메모리의 대역폭을 넓혀 많은 코어가 많은 작업을 받아 처리하는 것이 목표
- 병렬 처리(parallel processing)에 용이
	- 크고 복잡한 문제를 / 쉽고 간단한 여러 문제로 쪼갠 뒤 / 쉽고 간단한 문제를 처리할 수 있는 수단을 동시에 동원
- 자체적으로 캐시 메모리 보유
- 수십 기가바이트에 이르는 메모리 보유
- 단순한 연산을 빠르게, 병렬적으로 수행하기 위한 장치
- **보조프로세서(coprocessor)**
	- GPU가 CPU의 산술 연산을 보조함
- CUDA와 같은 프로그래밍 모델을 통해 직접 소스코드로 수행할 작업을 지정할 수 있음
